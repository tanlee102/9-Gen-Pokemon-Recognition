{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "680xTUC45GBZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow tensorflow-addons pandas matplotlib"
      ],
      "metadata": {
        "id": "hxSIcUSd5KY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/PokemonGenFinal\n",
        "!unzip /content/drive/MyDrive/PokemonGenFinal.zip -d /content/drive/MyDrive/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MtzmlQFb5L5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data from PokemonDataset.csv\n",
        "csv_file_path = \"/content/drive/MyDrive/PokemonGenFinal/pokemon_images.csv\"  # Ensure the file path is correct\n",
        "data_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Add prefix to the image_path column\n",
        "base_path = \"/content/drive/MyDrive/PokemonGenFinal/\"\n",
        "data_df['image_path'] = base_path + data_df['image_path'].astype(str)\n",
        "\n",
        "# Encode labels (name column)\n",
        "class_labels = data_df['name'].unique()  # Get unique names as class labels\n",
        "label_to_index = {label: idx for idx, label in enumerate(class_labels)}  # Create a mapping\n",
        "data_df['label'] = data_df['name'].map(label_to_index)  # Map names to numerical labels\n",
        "\n",
        "# Filter out classes with only one instance\n",
        "data_df = data_df[data_df['label'].map(data_df['label'].value_counts()) > 1]\n",
        "\n",
        "# Train-test split\n",
        "train_df, val_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'])\n",
        "\n",
        "# Preprocessing function\n",
        "IMG_SIZE = 224  # MobileNetV3Large input size is 224x224\n",
        "def preprocess_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)  # Read the image file\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Decode the image\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])  # Resize to IMG_SIZE\n",
        "    image = tf.keras.applications.mobilenet_v3.preprocess_input(image)  # Preprocess for MobileNetV3\n",
        "    return image, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "def create_dataset(df):\n",
        "    file_paths = df['image_path'].values  # Extract file paths\n",
        "    labels = df['label'].values  # Extract labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))  # Create a TensorFlow dataset\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)  # Preprocess images\n",
        "    dataset = dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)  # Optimize dataset\n",
        "    return dataset\n",
        "\n",
        "# Create train and validation datasets\n",
        "train_dataset = create_dataset(train_df)\n",
        "val_dataset = create_dataset(val_df)\n",
        "\n",
        "# Print a summary\n",
        "print(f\"Number of training samples: {len(train_df)}\")\n",
        "print(f\"Number of validation samples: {len(val_df)}\")\n",
        "print(f\"Class to label mapping: {label_to_index}\")"
      ],
      "metadata": {
        "id": "x79IaY0S5Ox9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "fine_tune_model = load_model(\"/content/drive/MyDrive/pre_train_mobile.keras\")\n",
        "\n",
        "for i, layer in enumerate(fine_tune_model.layers):\n",
        "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")"
      ],
      "metadata": {
        "id": "srhdSAza5p9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "results = fine_tune_model.evaluate(val_dataset)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"\\nValidation Results:\")\n",
        "for metric_name, metric_value in zip(fine_tune_model.metrics_names, results):\n",
        "    print(f\"{metric_name}: {metric_value}\")"
      ],
      "metadata": {
        "id": "4hHAqWvZ6Tt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model (MobileNetV3Large)\n",
        "for layer in fine_tune_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "for i, layer in enumerate(fine_tune_model.layers):\n",
        "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")"
      ],
      "metadata": {
        "id": "xOwxjc446fmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-Tuning\n",
        "fine_tune_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "history_fine_tune = fine_tune_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=25\n",
        ")"
      ],
      "metadata": {
        "id": "mX3hsZJf51Jm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}