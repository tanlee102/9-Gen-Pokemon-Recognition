{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjPuGqxPkrT7x58SR8H8u+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ybl8ZyIi2fxe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install --upgrade tensorflow tensorflow-addons pandas matplotlib"],"metadata":{"id":"KUx0wdvR21p-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/drive/MyDrive/PokemonGenFinal\n","!unzip /content/drive/MyDrive/PokemonGenFinal.zip -d /content/drive/MyDrive/"],"metadata":{"id":"dt4LjIO523rr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","# Load data from PokemonDataset.csv\n","csv_file_path = \"/content/drive/MyDrive/PokemonGenFinal/pokemon_images.csv\"  # Ensure the file path is correct\n","data_df = pd.read_csv(csv_file_path)\n","\n","# Add prefix to the image_path column\n","base_path = \"/content/drive/MyDrive/PokemonGenFinal/\"\n","data_df['image_path'] = base_path + data_df['image_path'].astype(str)\n","\n","# Encode labels (name column)\n","class_labels = data_df['name'].unique()  # Get unique names as class labels\n","label_to_index = {label: idx for idx, label in enumerate(class_labels)}  # Create a mapping\n","data_df['label'] = data_df['name'].map(label_to_index)  # Map names to numerical labels\n","\n","# Filter out classes with only one instance\n","data_df = data_df[data_df['label'].map(data_df['label'].value_counts()) > 1]\n","\n","# Train-test split\n","train_df, val_df = train_test_split(data_df, test_size=0.2, stratify=data_df['label'])\n","\n","# Preprocessing function\n","IMG_SIZE = 224  # MobileNetV3Large input size is 224x224\n","def preprocess_image(image_path, label):\n","    image = tf.io.read_file(image_path)  # Read the image file\n","    image = tf.image.decode_jpeg(image, channels=3)  # Decode the image\n","    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])  # Resize to IMG_SIZE\n","    image = tf.keras.applications.mobilenet_v3.preprocess_input(image)  # Preprocess for MobileNetV3\n","    return image, label\n","\n","# Create TensorFlow datasets\n","def create_dataset(df):\n","    file_paths = df['image_path'].values  # Extract file paths\n","    labels = df['label'].values  # Extract labels\n","    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))  # Create a TensorFlow dataset\n","    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)  # Preprocess images\n","    dataset = dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)  # Optimize dataset\n","    return dataset\n","\n","# Create train and validation datasets\n","train_dataset = create_dataset(train_df)\n","val_dataset = create_dataset(val_df)\n","\n","# Print a summary\n","print(f\"Number of training samples: {len(train_df)}\")\n","print(f\"Number of validation samples: {len(val_df)}\")\n","print(f\"Class to label mapping: {label_to_index}\")"],"metadata":{"id":"-sKTA9qQ26Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models, regularizers\n","from tensorflow.keras.applications import MobileNetV3Large\n","\n","# Define the number of classes\n","num_classes = len(class_labels)\n","\n","# Load pre-trained MobileNetV3 with frozen weights\n","base_model = MobileNetV3Large(\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),  # Change shape based on your data\n","    include_top=False,  # Exclude classifier head\n","    weights='imagenet'  # Pre-trained on ImageNet\n",")\n","base_model.trainable = False  # Freeze the base model initially\n","\n","# Build the model\n","model = models.Sequential([\n","    # Data Augmentation Layers\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1),\n","    layers.RandomContrast(0.2),\n","    layers.RandomTranslation(0.1, 0.1),\n","\n","    # Pre-trained backbone\n","    base_model,\n","\n","    # Bottleneck block with correct BatchNorm-Activation order\n","    layers.Conv2D(256, (1, 1), padding='same', use_bias=False),  # No activation here\n","    layers.BatchNormalization(),\n","    layers.Activation('relu'),  # Relu activation after BatchNorm\n","\n","    layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False),\n","    layers.BatchNormalization(),\n","    layers.Activation('relu'),\n","\n","    layers.Conv2D(512, (1, 1), padding='same', use_bias=False),\n","    layers.BatchNormalization(),\n","    layers.Activation('relu'),\n","\n","    # Global pooling\n","    layers.GlobalAveragePooling2D(),\n","\n","    # Dense block with dropout and regularization\n","    layers.Dense(768, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n","    layers.Dropout(0.3),  # Increased dropout for stronger regularization\n","\n","    # Output layer\n","    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes as needed\n","])\n","\n","for i, layer in enumerate(model.layers):\n","    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")"],"metadata":{"id":"HzvYYPDy35xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Phase 1: Initial Training\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['sparse_categorical_accuracy'])\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=37\n",")"],"metadata":{"id":"TqFOFeTN4E4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model in the Keras format\n","model.save(\"/content/drive/MyDrive/pre_train_mobile.keras\")\n","print(\"Model saved successfully in Keras format!\")"],"metadata":{"id":"TAobsKPC4KVP"},"execution_count":null,"outputs":[]}]}